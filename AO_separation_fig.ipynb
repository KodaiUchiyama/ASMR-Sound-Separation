{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/kody.uchiyama/.local/share/virtualenvs/asmr_sound_separation-Q8KNsWuG/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/kody.uchiyama/.local/share/virtualenvs/asmr_sound_separation-Q8KNsWuG/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/kody.uchiyama/.local/share/virtualenvs/asmr_sound_separation-Q8KNsWuG/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/kody.uchiyama/.local/share/virtualenvs/asmr_sound_separation-Q8KNsWuG/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/kody.uchiyama/.local/share/virtualenvs/asmr_sound_separation-Q8KNsWuG/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/kody.uchiyama/.local/share/virtualenvs/asmr_sound_separation-Q8KNsWuG/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append ('./model/model')\n",
    "sys.path.append ('./model/utils')\n",
    "from keras.models import load_model\n",
    "#from option import ModelMGPU\n",
    "import os\n",
    "import scipy.io.wavfile as wavfile\n",
    "import numpy as np\n",
    "import utils\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "from matplotlib import cm\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#parameters\n",
    "people = 2\n",
    "num_gpu=1\n",
    "\n",
    "#path\n",
    "# exp new\n",
    "model_path = './saved_AO_models/AOmodel-1p-001-0.24099.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialing Parameters......\n",
      "Loading data ......\n"
     ]
    }
   ],
   "source": [
    "database = './data/AV_model_database/mix/'\n",
    "face_emb_path = '/home/kody.uchiyama/speech_separation-master/data/video/face1022_emb/'\n",
    "food_truth_path='/home/kody.uchiyama/asmr_sound_separation/data/AV_model_database/food_single/'\n",
    "print('Initialing Parameters......')\n",
    "\n",
    "#loading data\n",
    "print('Loading data ......')\n",
    "test_file = []\n",
    "with open('./data/AV_log/AVdataset_test.txt','r') as f:\n",
    "    test_file = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_name(line,people=people,database=database,face_emb_path=face_emb_path, food_truth_path=food_truth_path):\n",
    "    parts = line.split() # get each name of file for one testset\n",
    "    # mix_17-145_00091.npy crm_17-145_00091_17-145.npy 17-145_face_emb.npy\n",
    "    mix_str = parts[0]\n",
    "    name_list = mix_str.replace('.npy','')\n",
    "    name_list = name_list.replace('mix_','')\n",
    "    names = name_list.split('_')\n",
    "    single_idxs = [] # 17-145, 00091\n",
    "    for i in range(2):\n",
    "        single_idxs.append(names[i])\n",
    "    file_path1 = database + mix_str\n",
    "    file_path2 = face_emb_path + parts[2]\n",
    "    file_path3 = food_truth_path + single_idxs[0] + '.npy'\n",
    "    mix = np.load(file_path1)\n",
    "    face_emb = np.load(file_path2)\n",
    "    food_truth_feature = np.load(file_path3)\n",
    "    #face_emb_ex = np.zeros((1,75,1,1792,1))\n",
    "    #face_emb_ex[1,:,:,:,1] = face_emb\n",
    "    #for i in range(1):\n",
    "    #    face_emb_ex[1,:,:,:,i] = face_emb\n",
    "\n",
    "    return mix,single_idxs,face_emb, food_truth_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kody.uchiyama/.local/share/virtualenvs/asmr_sound_separation-Q8KNsWuG/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/kody.uchiyama/.local/share/virtualenvs/asmr_sound_separation-Q8KNsWuG/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "#result predict\n",
    "ao_model = load_model(model_path,custom_objects={'tf':tf})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### PLOT RESULTS\n",
    "def plot_spectrogram(single_idxs, mix, cRM, flag_string):\n",
    "    # top, bottom title\n",
    "    if flag_string == 'mix-crm':\n",
    "        top_title = 'Input'\n",
    "        bottom_title = 'Mask'\n",
    "    else:\n",
    "        top_title = 'Ground truth'\n",
    "        bottom_title = 'Result'\n",
    "    \n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.imshow(mix, aspect='auto')\n",
    "    plt.ylim(0,256)\n",
    "    plt.title(top_title)\n",
    "    plt.ylabel('Frequency bands')\n",
    "    plt.xlabel('Time')\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.imshow(cRM, aspect='auto')\n",
    "    plt.ylim(0,256)\n",
    "    plt.title(bottom_title)\n",
    "    plt.ylabel('Frequency bands')\n",
    "    plt.xlabel('Time')\n",
    "    plt.colorbar()\n",
    "    \n",
    "    plt.tight_layout()#図の調整\n",
    "    plt.draw()\n",
    "\n",
    "    #生成されたスペクトログラムと正解値スペクトログラムを比較表示、保存\n",
    "    # フォルダの作成\n",
    "    # make output directory\n",
    "    if flag_string == 'mix-crm':\n",
    "        folder = 'predict_AO_mix_crm_fig/'\n",
    "    else:\n",
    "        folder = 'predict_AO_food_f_fig/'\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    plt.savefig(folder + \"%s_%s.png\"%(single_idxs[0],single_idxs[1]))  # ../graphs/predicted_spectrums/{lr:0.000597}-{ws:0.000759}/1.png\n",
    "    plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(298, 257, 2)\n",
      "(75, 1, 1792)\n",
      "(1, 298, 257, 2)\n",
      "(1, 75, 1, 1792, 1)\n",
      "(1, 298, 257, 2, 1)\n",
      "(298, 257, 2)\n",
      "(75, 1, 1792)\n",
      "(1, 298, 257, 2)\n",
      "(1, 75, 1, 1792, 1)\n",
      "(1, 298, 257, 2, 1)\n",
      "(298, 257, 2)\n",
      "(75, 1, 1792)\n",
      "(1, 298, 257, 2)\n",
      "(1, 75, 1, 1792, 1)\n",
      "(1, 298, 257, 2, 1)\n",
      "(298, 257, 2)\n",
      "(75, 1, 1792)\n",
      "(1, 298, 257, 2)\n",
      "(1, 75, 1, 1792, 1)\n",
      "(1, 298, 257, 2, 1)\n",
      "(298, 257, 2)\n",
      "(75, 1, 1792)\n",
      "(1, 298, 257, 2)\n",
      "(1, 75, 1, 1792, 1)\n",
      "(1, 298, 257, 2, 1)\n",
      "(298, 257, 2)\n",
      "(75, 1, 1792)\n",
      "(1, 298, 257, 2)\n",
      "(1, 75, 1, 1792, 1)\n",
      "(1, 298, 257, 2, 1)\n",
      "(298, 257, 2)\n",
      "(75, 1, 1792)\n",
      "(1, 298, 257, 2)\n",
      "(1, 75, 1, 1792, 1)\n",
      "(1, 298, 257, 2, 1)\n",
      "(298, 257, 2)\n",
      "(75, 1, 1792)\n",
      "(1, 298, 257, 2)\n",
      "(1, 75, 1, 1792, 1)\n",
      "(1, 298, 257, 2, 1)\n",
      "(298, 257, 2)\n",
      "(75, 1, 1792)\n",
      "(1, 298, 257, 2)\n",
      "(1, 75, 1, 1792, 1)\n",
      "(1, 298, 257, 2, 1)\n",
      "(298, 257, 2)\n",
      "(75, 1, 1792)\n",
      "(1, 298, 257, 2)\n",
      "(1, 75, 1, 1792, 1)\n",
      "(1, 298, 257, 2, 1)\n",
      "(298, 257, 2)\n",
      "(75, 1, 1792)\n",
      "(1, 298, 257, 2)\n",
      "(1, 75, 1, 1792, 1)\n",
      "(1, 298, 257, 2, 1)\n",
      "(298, 257, 2)\n",
      "(75, 1, 1792)\n",
      "(1, 298, 257, 2)\n",
      "(1, 75, 1, 1792, 1)\n",
      "(1, 298, 257, 2, 1)\n",
      "(298, 257, 2)\n",
      "(75, 1, 1792)\n",
      "(1, 298, 257, 2)\n",
      "(1, 75, 1, 1792, 1)\n",
      "(1, 298, 257, 2, 1)\n",
      "(298, 257, 2)\n",
      "(75, 1, 1792)\n",
      "(1, 298, 257, 2)\n",
      "(1, 75, 1, 1792, 1)\n",
      "(1, 298, 257, 2, 1)\n",
      "(298, 257, 2)\n",
      "(75, 1, 1792)\n",
      "(1, 298, 257, 2)\n",
      "(1, 75, 1, 1792, 1)\n",
      "(1, 298, 257, 2, 1)\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "if num_gpu<=1:\n",
    "    for line in test_file:\n",
    "        mix,single_idxs,face_emb, food_truth_feature = get_data_name(line,people,database,face_emb_path)\n",
    "        print(mix.shape) # (298, 257, 2)\n",
    "        print(face_emb.shape) # (75, 1, 1792)\n",
    "        # モデル入力出力用に型変更\n",
    "        mix_ex = np.expand_dims(mix,axis=0)\n",
    "        face_emb_ex = np.expand_dims(face_emb,axis=0)\n",
    "        face_emb_ex = np.expand_dims(face_emb_ex,axis=4)\n",
    "        print(mix_ex.shape) #(1, 298, 257, 2)\n",
    "        print(face_emb_ex.shape) #(1, 75, 1, 1792, 1)\n",
    "        cRMs = ao_model.predict(mix_ex)\n",
    "        print(cRMs.shape) # (1, 298, 257, 2, 1)\n",
    "        cRMs = cRMs[0]\n",
    "        prefix =''\n",
    "        for idx in single_idxs:\n",
    "            prefix +=idx+'_'\n",
    "        cRM =cRMs[:,:,:,0]\n",
    "        assert cRM.shape ==(298,257,2)\n",
    "        # mixスペクトログラムにcRMマスクをかける\n",
    "        F = utils.fast_icRM(mix,cRM)\n",
    "        T = utils.fast_istft(F,power=False)\n",
    "        \n",
    "        # モデル入力出力用に型変更\n",
    "        cRM_ = utils.real_imag_shrink(cRM)\n",
    "        F_ = utils.real_imag_shrink(F)\n",
    "        mix_ = utils.real_imag_shrink(mix)\n",
    "        food_truth_feature_ = utils.real_imag_shrink(food_truth_feature)\n",
    "        \n",
    "        #マスクも複素数なので視覚化のため\n",
    "        cRM__ = abs(cRM_)\n",
    "        \n",
    "        #振幅スペクトログラムにlog（x）をかける\n",
    "        F__ = np.log(abs(F_))\n",
    "        mix__ = np.log(abs(mix_))\n",
    "        food_truth_feature__ = np.log(abs(food_truth_feature_))\n",
    "        \n",
    "        # plot\n",
    "        plot_spectrogram(single_idxs, mix__.T, cRM__.T, 'mix-crm')\n",
    "        plot_spectrogram(single_idxs, food_truth_feature__.T, F__.T, 'food-f')\n",
    "        \n",
    "        count = count + 1\n",
    "        if count == 15:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asmr_separation",
   "language": "python",
   "name": "asmr_separation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
